# -*- coding: utf-8 -*-
"""BDMH_A3_ANN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1JPgbekaGYNLNBzrJSvZxrd8v83d2cSwt
"""

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from keras.models import Sequential
from keras.layers import Dense,Dropout
from keras import optimizers

import csv
df_train=pd.read_csv("trainset.data")
df_test=pd.read_csv("testset.dat")
df_dipep_train=pd.read_csv("dipep_train.csv")
df_dipep_test=pd.read_csv("dipep_test.csv")

#MLP implementation
# dipep_train_col=df_dipep_train.columns
# print(dipep_train_col)
# train_attri=[]
# for i in range(1,len(dipep_train_col)):
#     train_attri.append(dipep_train_col[i])
# print(len(train_attri))
# dipep_test_col=df_dipep_test.columns
# test_attri=[]
# for i in range(1,len(dipep_test_col)):
#     test_attri.append(dipep_test_col[i])
# print(len(test_attri))

# y=df_train.Label.values
# print(len(y))
# x=df_dipep_train[train_attri]
# print(len(x))
# xtrain, xtest, ytrain, ytest = train_test_split(x,y,test_size=0.2)

# from sklearn.neural_network import MLPClassifier
# clf = MLPClassifier(solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(5, 2), random_state=1)
# clf.fit(xtrain, ytrain)
# MLPClassifier(alpha=1e-05, hidden_layer_sizes=(5, 2), random_state=1,solver='lbfgs')
# test_p=df_dipep_test[test_attri]
# y_pred_mlp=clf.predict(test_p)
# print(y_pred_mlp)

# list1=df_test["ID"]
# output_list=[]
# test_c=["ID","Label"]
# output_list.append(test_c)
# for i in range(len(list1)):
#     t=[]
#     t.append(list1[i])
#     t.append(y_pred_mlp[i])
#     output_list.append(t)

# import csv
# with open('BDMH_mlp.csv', 'w', newline='') as file:
#     writer = csv.writer(file, delimiter=',')
#     writer.writerows(output_list)

X = df_dipep_train.iloc[:, 1:].values
print(X)
Y = df_train.iloc[:, 1].values
print(Y)



cls = Sequential()
cls.add(Dense(100, input_dim=400, activation='tanh'))
cls.add(Dense(100, activation='tanh'))
# cls.add(Dropout(0.5))
cls.add(Dense(1, activation='sigmoid'))

sgd=optimizers.SGD(lr=0.01)
cls.compile(loss='binary_crossentropy',optimizer=sgd, metrics=['acc'])

cls.fit(X, Y, epochs=150, batch_size=100, verbose=2)

# hists=[]
# cls.fit(X, Y, epochs=150, batch_size=100, validation_split=0.1, verbose=2)
# hists.append(cls.history.history)

# import matplotlib.pyplot as plt
# acc = []
# val_acc = []
# for i in range(len(hists)):
#     acc += hists[i]["acc"]
#     val_acc += hists[i]["val_acc"]
# hist_df = pd.DataFrame({"# Epoch": [e for e in range(1,len(acc)+1)],"Accuracy": acc, "Val_accuracy": val_acc})
# hist_df.plot(x = "# Epoch", y = ["Accuracy","Val_accuracy"])
# plt.title("Accuracy vs Validation Accuracy")
# plt.show()

test_x=df_dipep_test.iloc[:,1:]

pred = cls.predict(test_x)
# pred = cls.predict_classes(test_x)
new_pred = [int(round(x[0])) for x in pred]
print(new_pred)



for n, i in enumerate(new_pred):
  if i==0:
    new_pred[n]=-1

print(new_pred)

list1=df_test["ID"]
output_list=[]
test_c=["ID","Label"]
output_list.append(test_c)
for i in range(len(list1)):
    t=[]
    t.append(list1[i])
    t.append(new_pred[i])
    output_list.append(t)

print(output_list)

import csv
with open('final_output2.csv', 'w', newline='') as file:
    writer = csv.writer(file, delimiter=',')
    writer.writerows(output_list)