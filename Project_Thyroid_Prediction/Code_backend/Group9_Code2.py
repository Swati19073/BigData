# -*- coding: utf-8 -*-
"""BDMH_Project_code.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bwzEEoX2HR0H14gTBKw0GfCrFa5YTaMB
"""

import numpy as np
import matplotlib.pyplot as plt
import statistics

"""**reading the data**"""

f = open("/content/drive/My Drive/ann-train.data","r")
train_data= f.read().splitlines(True)

train_data

"""###**TRAINING PART**

**creating data matrix**
"""

def create_matrix(data):
  data_matrix = []
  labels = []

  for line in data:
    temp = line.strip('\n').strip(' ').split()
    temp = list(map(float, temp))                   # convert string to float
    labels.append(temp[-1])                         # extracting last element because it is the label
    temp.pop(-1)                                    # remove the last element because it is the label and not required for training
    data_matrix.append(temp)

  return data_matrix,labels

data_matrix,labels = create_matrix(train_data)

data_matrix = np.asarray(data_matrix)
labels = np.asarray(labels)

data_matrix.shape

labels.shape

"""**Variance based feature selection**"""

variance = []

for i in range(0,21):
  temp = np.var(data_matrix[:,i])
  variance.append(temp)

median_v = statistics.median(variance)

"""*finding the features that have to be dropped*"""

dropped_features = []

for i in range(0,21):
  if(variance[i] < median_v):
    dropped_features.append(i)

dropped_features

len(dropped_features)

"""*reducing the features*"""

reduced_matrix = np.delete(data_matrix, np.s_[dropped_features], axis=1)

reduced_matrix.shape

"""**RNN MODEL**"""

import tensorflow as tf

from keras.models import Sequential 
from keras.layers import Dense, Activation

from sklearn.model_selection import KFold

kf = KFold(n_splits=10, random_state=1, shuffle=True)

model = Sequential()
model.add(Dense(256, activation='relu', input_dim=21))
model.add(Dense(128, activation='relu'))
model.add(Dense(32, activation='relu'))
model.add(Dense(4, activation='softmax'))
model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])

for train_index, test_index in kf.split(data_matrix):
    X_train, X_test = data_matrix[train_index], data_matrix[test_index]
    y_train, y_test = labels[train_index], labels[test_index]
    
    model.fit(X_train, y_train, epochs=15, batch_size=32)
    score = model.evaluate(X_test, y_test, batch_size=32)
    print(score)

# model.save("/content/drive/My Drive/rnn_model.h5")
model.save("rnn_model.h5")

"""**SVM MODEL**

**Tuning parameters for SVM**
"""

#  source : https://medium.com/@aneesha/svm-parameter-tuning-in-scikit-learn-using-gridsearchcv-2413c02125a0
#           https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html

from sklearn import svm
from sklearn.model_selection import GridSearchCV

def svc_param_selection(X, y, nfolds):
    Cs = [0.001, 0.01, 0.1, 1, 10]
    gammas = [0.001, 0.01, 0.1, 1]
    param_grid = {'C': Cs, 'gamma' : gammas}
    grid_search = GridSearchCV(svm.SVC(kernel='linear'), param_grid, cv=nfolds)
    grid_search.fit(X, y)
    grid_search.best_params_
    
    return grid_search.best_params_

ans = svc_param_selection(data_matrix,labels,10)
print(ans)

"""**Building the model**"""

from sklearn.model_selection import cross_val_score
from sklearn import svm

kf = KFold(n_splits=10, random_state=1, shuffle=True)

clf = svm.SVC(kernel='poly', gamma = 0.001, C=10,degree=2)

for train_index, test_index in kf.split(data_matrix):
    X_train, X_test = data_matrix[train_index], data_matrix[test_index]
    y_train, y_test = labels[train_index], labels[test_index]
    
    clf = clf.fit(X_train, y_train)
    scores = cross_val_score(clf, X_test, y_test, cv=8)
    print(scores)

model.save("svm_model.h5")

"""###**TESTING PART**

**reading the test data**
"""

f1 = open("/content/drive/My Drive/ann-test.data","r")
test_data= f1.read().splitlines(True)

test_data

"""**creating test matrix**"""

test_matrix,true_labels = create_matrix(test_data)

test_matrix = np.asarray(test_matrix)
true_labels = np.asarray(true_labels)

test_matrix.shape

true_labels.shape

"""**Heat Plot**"""

def heat_plot(y_true,y_pred,matrix):
  
  labels = ["1","2","3"]

  fig = plt.figure()
  ax = fig.add_subplot(111)
  cax = ax.matshow(matrix,cmap = 'tab20c')
  fig.colorbar(cax)
  ax.set_fc('y')
  ax.set_xticklabels([''] + labels)
  ax.set_yticklabels([''] + labels)

  # Loop over data dimensions and create text annotations.
  for i in range(3):
    for j in range(3):
      text = ax.text(j, i, matrix[i, j],ha="center", va="center", color="w")
  
  fig.tight_layout()
  plt.xlabel('Predicted')
  plt.ylabel('True')
  plt.show()

"""**Generate Predictions**

> Using RNN model
"""

pred_rnn = model.predict_classes(test_matrix)

from sklearn.metrics import accuracy_score

accuracy_score(true_labels, pred_rnn)

from sklearn.metrics import confusion_matrix

conf_rnn = confusion_matrix(true_labels, pred_rnn)

conf_rnn

heat_plot(true_labels,pred_rnn,conf_rnn)

precision_recall_fscore_support(true_labels, pred_rnn, average='macro')

"""> Using SVM model"""

pred_svm = clf.predict(test_matrix)

from sklearn.metrics import accuracy_score

accuracy_score(true_labels, pred_svm)

from sklearn.metrics import confusion_matrix

conf_svm = confusion_matrix(true_labels, pred_svm)

conf_svm

heat_plot(true_labels,pred_svm,conf_svm)

precision_recall_fscore_support(true_labels, pred_svm, average='micro')

"""> **Training SVM model after feature selection**"""

ans = svc_param_selection(reduced_matrix,labels,10)
print(ans)

from sklearn.model_selection import cross_val_score
from sklearn import svm

kf = KFold(n_splits=10, random_state=1, shuffle=True)

clf_2 = svm.SVC(kernel='poly', gamma = 0.001, C=0.001,degree=2)

for train_index, test_index in kf.split(reduced_matrix):
    X_train, X_test = reduced_matrix[train_index], reduced_matrix[test_index]
    y_train, y_test = labels[train_index], labels[test_index]
    
    clf_2 = clf_2.fit(X_train, y_train)
    scores = cross_val_score(clf, X_test, y_test, cv=8)
    print(scores)

test_matrix_2 = np.delete(test_matrix, np.s_[dropped_features], axis=1)

test_matrix_2.shape

pred_svm_2 = clf_2.predict(test_matrix_2)

accuracy_score(true_labels, pred_svm_2)

confusion_matrix(true_labels, pred_svm_2)

from sklearn.metrics import precision_recall_fscore_support
precision_recall_fscore_support(true_labels,pred_svm_2, average='micro')

